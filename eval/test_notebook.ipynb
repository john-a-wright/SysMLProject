{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sit1m_data_preprocessing import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Sift1M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:04<00:00,  4.84s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:04<00:00,  4.84s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:04<00:00,  4.84s/ url]\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\n",
      "Dl Size...: 100%|██████████| 525128288/525128288 [00:04<00:00, 108443473.68 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:04<00:00,  4.84s/ url]\n"
     ]
    }
   ],
   "source": [
    "# download (if not downloaded) and build sift1m dataset\n",
    "dataset_download_path = \"D:/College/SysML/dataset\" # a folder to cache dataset contents that are downloaded\n",
    "splits = build_sift1m(dataset_download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train split array\n",
      "Found existing train data file\n",
      "[[  0.  16.  35. ...  25.  23.   1.]\n",
      " [ 14.  35.  19. ...  11.  21.  33.]\n",
      " [  0.   1.   5. ...   4.  23.  10.]\n",
      " ...\n",
      " [ 30.  12.  12. ...  50.  10.   0.]\n",
      " [  0.   5.  12. ...   1.   2.  13.]\n",
      " [114.  31.   0. ...  25.  16.   0.]]\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# make and print train split input array (1 million embedding arrays of length 128)\n",
    "train_input_array = get_train_split(splits)\n",
    "\n",
    "print(train_input_array)\n",
    "print(train_input_array.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building test split array\n",
      "Progress: 50.0%\n",
      "Progress: 100.0%\n",
      "[[  1.   3.  11. ...  42.  48.  11.]\n",
      " [ 40.  25.  11. ...   3.  19.  13.]\n",
      " [ 28.   4.   3. ...   2.  54.  47.]\n",
      " ...\n",
      " [  0.  15.  64. ...   3.  62. 118.]\n",
      " [131.   2.   0. ...   7.   0.   0.]\n",
      " [ 23.   0.   0. ...  79.  16.   4.]]\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# make and print test split input array (10k embedding arrays of length 128)\n",
    "test_input_array, neighbors = get_test_split(splits)\n",
    "\n",
    "print(test_input_array)\n",
    "print(test_input_array.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PQ Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = train_input_array.shape[1]\n",
    "numSubVectors = 8\n",
    "subVectorBits = 8\n",
    "\n",
    "pq = faiss.IndexPQ(dim, numSubVectors, subVectorBits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.train(train_input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.add(train_input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "distances, indexes = pq.search(test_input_array[:10000], k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5851\n"
     ]
    }
   ],
   "source": [
    "t = 25\n",
    "i = 0\n",
    "relevantPercent = []\n",
    "\n",
    "for entry in neighbors:\n",
    "\n",
    "    topIndexs = []\n",
    "    for x in range(t):\n",
    "        index_dict = entry[x]\n",
    "        topIndexs.append(index_dict[\"index\"])\n",
    "\n",
    "    search_results = indexes[i]\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for x in search_results:\n",
    "        if x in topIndexs:\n",
    "            count+=1\n",
    "\n",
    "    relevantPercent.append(count/k)\n",
    "    \n",
    "    i=i+1\n",
    "        \n",
    "\n",
    "print(sum(relevantPercent) / len(relevantPercent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-FSQ VQVAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, input_dim, codebook_size, codebook_dim):\n",
    "        super(VQVAE, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.codebook_size = codebook_size\n",
    "        self.codebook_dim = codebook_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, codebook_dim)\n",
    "        )\n",
    "        \n",
    "        # Codebook\n",
    "        self.codebook = nn.Embedding(codebook_size, codebook_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(codebook_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_dim)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "\n",
    "    def quantize(self, z):\n",
    "        # Find nearest embedding in the codebook\n",
    "        z = z.unsqueeze(2)\n",
    "        distances = torch.norm(z - self.codebook.weight.unsqueeze(0), dim=1)\n",
    "        indices = torch.argmin(distances, dim=1)\n",
    "        quantized = self.codebook(indices)\n",
    "        return quantized, indices\n",
    "\n",
    "    def decode(self, z):\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        quantized, indices = self.quantize(z)\n",
    "        x_recon = self.decode(quantized)\n",
    "        return x_recon, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae = VQVAE(input_dim=128, codebook_size=512, codebook_dim=64)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(vqvae.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        # You may need to preprocess the data here, such as converting to tensor\n",
    "        return torch.tensor(sample, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_input_array)\n",
    "print(len(train_dataset))\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3\n",
    "seed = 44\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 64\n",
    "D = train_input_array.shape[1]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "torch.random.manual_seed(seed)\n",
    "model = VQVAE(input_dim=128, codebook_size=512, codebook_dim=64)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "log_loss = np.array([])\n",
    "for i_epoch in range(EPOCHS):\n",
    "    dataloader = DataLoader(train_input_array, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "        x = batch.to(device)\n",
    "        x = x.to(torch.float)\n",
    "        x = x.reshape(BATCH_SIZE, 1, D)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out, indices = model(x)\n",
    "\n",
    "        rec_loss = loss(out, x)\n",
    "        rec_loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {i_epoch}, Batch: {i_batch}, Loss: {rec_loss}\")\n",
    "        log_loss = np.append(log_loss,np.log(rec_loss.detach().cpu().numpy()))\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': i_epoch,\n",
    "            'model_state_dict':  model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'log_loss': log_loss,\n",
    "        }, f\"vqvae_vimeo_checkpoint.pth\")\n",
    "\n",
    "plt.plot(log_loss)\n",
    "plt.savefig(\"vqvae_vimeo_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(vqvae.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vqvae.to(device)\n",
    "\n",
    "# Training loop\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    vqvae.train()\n",
    "    total_recon_loss = 0.0\n",
    "    total_commitment_loss = 0.0\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        inputs = data.to(device)\n",
    "        recon_batch, indices = vqvae(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        recon_loss = criterion(recon_batch, inputs)\n",
    "        commitment_loss = torch.mean(torch.norm((indices.float() - vqvae.codebook(indices)) ** 2))\n",
    "        loss = recon_loss + commitment_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        total_recon_loss += recon_loss.item()\n",
    "        total_commitment_loss += commitment_loss.item()\n",
    "        \n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Recon Loss: {total_recon_loss / len(train_loader):.4f}, Commitment Loss: {total_commitment_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learned Compression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tensorflow as tf\n",
    "\n",
    "from compressai.models import CompressionModel\n",
    "from compressai.models.utils import conv, deconv\n",
    "from compressai.entropy_models import EntropyBottleneck\n",
    "from compressor_compressai import Network\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from compressai.ops.parametrizers import NonNegativeParametrizer\n",
    "\n",
    "import zlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelToSpatial(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, spatial_dim = x.size()\n",
    "        return x.view(batch_size, spatial_dim, channels)\n",
    "\n",
    "\n",
    "class Network(CompressionModel):\n",
    "    def __init__(self, compressed_d = 64, uncompressed_d = 128):\n",
    "        \"\"\"\n",
    "        compressed_d = compressed dimension of the embedding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.entropy_bottleneck = EntropyBottleneck(1)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, compressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(compressed_d, compressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(compressed_d, compressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(compressed_d, compressed_d//2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(compressed_d//2, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(compressed_d),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(compressed_d)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(32, compressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(compressed_d, uncompressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(uncompressed_d, uncompressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(uncompressed_d, uncompressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(uncompressed_d, uncompressed_d//2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(uncompressed_d//2, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(uncompressed_d),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(uncompressed_d)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.encoder(x)\n",
    "        \n",
    "        y_hat, y_likelihoods = self.entropy_bottleneck(y)\n",
    "\n",
    "        x_hat = self.decoder(y_hat)\n",
    "\n",
    "        return x_hat, y_likelihoods\n",
    "    \n",
    "    def get_compressed_embeddings(self, x):\n",
    "        y = self.encoder(x)\n",
    "        \n",
    "        y_hat, y_likelihoods = self.entropy_bottleneck(y)\n",
    "\n",
    "        return y_hat, y_likelihoods\n",
    "    \n",
    "    def decode_compressed_embeddings(self, y_hat):\n",
    "        \n",
    "        x_hat = self.decoder(y_hat)\n",
    "\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"GDN_1d\", \"GDN1_1d\"]\n",
    "\n",
    "#zlib\n",
    "\n",
    "class GDN_1d(nn.Module):\n",
    "    r\"\"\"Generalized Divisive Normalization layer.\n",
    "\n",
    "    Introduced in `\"Density Modeling of Images Using a Generalized Normalization\n",
    "    Transformation\" <https://arxiv.org/abs/1511.06281>`_,\n",
    "    by Balle Johannes, Valero Laparra, and Eero P. Simoncelli, (2016).\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       y[i] = \\frac{x[i]}{\\sqrt{\\beta[i] + \\sum_j(\\gamma[j, i] * x[j]^2)}}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        inverse: bool = False,\n",
    "        beta_min: float = 1e-6,\n",
    "        gamma_init: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        beta_min = float(beta_min)\n",
    "        gamma_init = float(gamma_init)\n",
    "        self.inverse = bool(inverse)\n",
    "\n",
    "        self.beta_reparam = NonNegativeParametrizer(minimum=beta_min)\n",
    "        beta = torch.ones(in_channels)\n",
    "        beta = self.beta_reparam.init(beta)\n",
    "        self.beta = nn.Parameter(beta)\n",
    "\n",
    "        self.gamma_reparam = NonNegativeParametrizer()\n",
    "        gamma = gamma_init * torch.eye(in_channels)\n",
    "        gamma = self.gamma_reparam.init(gamma)\n",
    "        self.gamma = nn.Parameter(gamma)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        _, C, _ = x.size()\n",
    "\n",
    "        beta = self.beta_reparam(self.beta)\n",
    "        gamma = self.gamma_reparam(self.gamma)\n",
    "        gamma = gamma.reshape(C, C, 1)\n",
    "        norm = F.conv1d(x**2, gamma, beta)\n",
    "\n",
    "        if self.inverse:\n",
    "            norm = torch.sqrt(norm)\n",
    "        else:\n",
    "            norm = torch.rsqrt(norm)\n",
    "\n",
    "        out = x * norm\n",
    "\n",
    "        return out\n",
    "\n",
    "class GDN1_1d(GDN_1d):\n",
    "    r\"\"\"Simplified GDN layer.\n",
    "\n",
    "    Introduced in `\"Computationally Efficient Neural Image Compression\"\n",
    "    <http://arxiv.org/abs/1912.08771>`_, by Johnston Nick, Elad Eban, Ariel\n",
    "    Gordon, and Johannes Ballé, (2019).\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        y[i] = \\frac{x[i]}{\\beta[i] + \\sum_j(\\gamma[j, i] * |x[j]|}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        _, C, _ = x.size()\n",
    "\n",
    "        beta = self.beta_reparam(self.beta)\n",
    "        gamma = self.gamma_reparam(self.gamma)\n",
    "        gamma = gamma.reshape(C, C, 1)\n",
    "        norm = F.conv1d(torch.abs(x), gamma, beta)\n",
    "\n",
    "        if not self.inverse:\n",
    "            norm = 1.0 / norm\n",
    "\n",
    "        out = x * norm\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelToSpatial(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, spatial_dim = x.size()\n",
    "        return x.view(batch_size, spatial_dim, channels)\n",
    "\n",
    "\n",
    "class Network(CompressionModel):\n",
    "    def __init__(self, compressed_d = 64, uncompressed_d = 128):\n",
    "        \"\"\"\n",
    "        compressed_d = compressed dimension of the embedding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.entropy_bottleneck = EntropyBottleneck(1)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, compressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            GDN1_1d(compressed_d),\n",
    "            nn.Conv1d(compressed_d, compressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(compressed_d, compressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            GDN1_1d(compressed_d),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(compressed_d, compressed_d//2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(compressed_d//2, 1, kernel_size=3, stride=1, padding=1),\n",
    "            GDN1_1d(1),\n",
    "            nn.LazyLinear(compressed_d),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LazyLinear(compressed_d),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(32, compressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(compressed_d),\n",
    "            nn.ConvTranspose1d(compressed_d, uncompressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(uncompressed_d, uncompressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(uncompressed_d),\n",
    "            nn.ConvTranspose1d(uncompressed_d, uncompressed_d, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(uncompressed_d, uncompressed_d//2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(uncompressed_d//2, uncompressed_d//2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(uncompressed_d//2, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(uncompressed_d),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LazyLinear(uncompressed_d)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.encoder(x)\n",
    "        \n",
    "        y_hat, y_likelihoods = self.entropy_bottleneck(y)\n",
    "\n",
    "        x_hat = self.decoder(y_hat)\n",
    "\n",
    "        return x_hat, y_likelihoods\n",
    "    \n",
    "    def get_compressed_embeddings(self, x):\n",
    "        y = self.encoder(x)\n",
    "        \n",
    "        y_hat, y_likelihoods = self.entropy_bottleneck(y)\n",
    "\n",
    "        return y_hat, y_likelihoods\n",
    "    \n",
    "    def decode_compressed_embeddings(self, y_hat):\n",
    "        \n",
    "        x_hat = self.decoder(y_hat)\n",
    "\n",
    "        return x_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# hyperparamters    \n",
    "seed = 44\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "lmbda = 1 # parameter for bitrate distortion tradeoff\n",
    "\n",
    "torch.random.manual_seed(seed)\n",
    "model = Network(64).to(\"cuda\")\n",
    "model.train()\n",
    "\n",
    "# parameters\n",
    "parameters = set(p for n, p in model.named_parameters() if not n.endswith(\".quantiles\"))\n",
    "aux_parameters = set(p for n, p in model.named_parameters() if n.endswith(\".quantiles\"))\n",
    "optimizer = optim.Adam(parameters, lr=1e-4)\n",
    "aux_optimizer = optim.Adam(aux_parameters, lr=1e-3)\n",
    "\n",
    "D = train_input_array.shape[1]\n",
    "\n",
    "loss_arr = np.array([])\n",
    "aux_loss_arr = np.array([])\n",
    "mse_loss_arr = np.array([])\n",
    "for i_epoch in range(EPOCHS):\n",
    "    dataloader = DataLoader(train_input_array, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "        x = batch.to(\"cuda\")\n",
    "        x = x.to(torch.float)\n",
    "        x = x.reshape(BATCH_SIZE, 1, D)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        aux_optimizer.zero_grad()\n",
    "\n",
    "        x_hat, y_likelihoods = model(x)\n",
    "\n",
    "        # bitrate of the quantized latent\n",
    "        N, _, L = x.size()\n",
    "        num_logits = N * L\n",
    "        bpp_loss = torch.log(y_likelihoods).sum() / (-math.log(2) * num_logits)\n",
    "\n",
    "        # mean square error\n",
    "        mse_loss = F.mse_loss(x, x_hat)\n",
    "\n",
    "        # final loss term\n",
    "        loss = mse_loss + lmbda * bpp_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        aux_loss = model.aux_loss()\n",
    "        aux_optimizer.step()\n",
    "        print(f\"Epoch: {i_epoch}, Batch: {i_batch}, loss: {loss}, aux_loss: {aux_loss}\")\n",
    "        loss_arr = np.append(loss_arr,loss.detach().cpu().numpy())\n",
    "        aux_loss_arr = np.append(aux_loss_arr,aux_loss.detach().cpu().numpy())\n",
    "        mse_loss_arr = np.append(mse_loss_arr,mse_loss.detach().cpu().numpy())\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': i_epoch,\n",
    "            'model_state_dict':  model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss_arr': loss_arr,\n",
    "            'aux_loss_arr': aux_loss_arr,\n",
    "            'mse_loss_arr': mse_loss_arr\n",
    "        }, f\"compressai_losses.pth\")\n",
    "\n",
    "plt.plot(loss_arr)\n",
    "plt.plot(aux_loss_arr)\n",
    "plt.savefig(\"compressai_losses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.0\n",
      "-124.0\n",
      "Original size: 64\n",
      "Compressed size: 160\n",
      "[  52.   31.   -8. -114.  -55.   45.   68.  -68.   48.  -61.   60.  -84.\n",
      "  -33.   60.  -75.  -67. -105.   30.   68.  -77.   67.  -63.   89.   52.\n",
      "  -75.   80.   83.  -96.  -69.   85.   85.  -89.   52. -100.   50.   76.\n",
      "  -51. -100.    5.  -88.   79.  -35.   75.  -17.   85.   53.  -97.   -4.\n",
      " -114.  -83.  -32.  109.   52.  -80.  -59.   83.   69.   87.  -94.  -78.\n",
      "  -88.   58.   61.  -58.]\n",
      "[120, 218, 45, 143, 33, 14, 194, 64, 16, 69, 191, 64, 114, 28, 14, 208, 86, 33, 16, 21, 72, 14, 80, 129, 64, 32, 17, 40, 66, 122, 128, 134, 16, 66, 86, 53, 4, 65, 72, 53, 162, 29, 133, 70, 162, 57, 0, 18, 201, 219, 204, 138, 151, 55, 243, 51, 187, 179, 43, 149, 133, 244, 203, 37, 13, 210, 199, 164, 5, 76, 200, 246, 17, 234, 12, 175, 241, 10, 95, 240, 40, 213, 13, 222, 193, 11, 190, 185, 207, 31, 99, 134, 55, 184, 195, 101, 154, 11, 184, 133, 158, 186, 134, 107, 225, 116, 230, 51, 79, 60, 197, 7, 152, 153, 247, 33, 147, 238, 248, 76, 54, 198, 77, 124, 207, 224, 231, 230, 96, 100, 219, 222, 223, 220, 130, 224, 157, 118, 6, 234, 165, 249, 206, 26, 110, 240, 160, 63, 153, 223, 89, 197, 63, 65, 101, 127, 19, 87, 67, 131]\n"
     ]
    }
   ],
   "source": [
    "# Compressed Embeddings Playground\n",
    "\n",
    "model = Network(64)\n",
    "\n",
    "checkpoint = torch.load(\"compressai_losses_final.pth\",map_location=\"cuda\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# for stacking tensors back into numpy array\n",
    "tensor_list = []\n",
    "\n",
    "test_dataloader = DataLoader(test_input_array, batch_size=1, shuffle=False)\n",
    "for i_batch, batch in enumerate(test_dataloader):\n",
    "        x = batch.to(\"cuda\")\n",
    "        x = x.to(torch.float)\n",
    "        x = x.reshape(1, 1, 128)\n",
    "\n",
    "        #print(x)\n",
    "        #x_hat, y_likelihoods = model(x)\n",
    "        #print(x_hat.to(torch.int))\n",
    "\n",
    "        y_hat, y_likelihoods = model.get_compressed_embeddings(x)\n",
    "\n",
    "        y_hat = y_hat.reshape(64)\n",
    "\n",
    "        tensor_list.append(y_hat)\n",
    "\n",
    "        if i_batch >= 10:\n",
    "                break\n",
    "\n",
    "\n",
    "combined_tensor = torch.stack(tensor_list)\n",
    "compressed_embeddings = combined_tensor.detach().cpu().numpy()\n",
    "#print(compressed_embeddings)\n",
    "\n",
    "print(max(compressed_embeddings.flatten()))\n",
    "print(min(compressed_embeddings.flatten()))\n",
    "\n",
    "\n",
    "data = compressed_embeddings[0]\n",
    "\n",
    "# Compress the data using zlib\n",
    "compressed_data = zlib.compress(data, level=9)\n",
    "\n",
    "print(\"Original size:\", len(data))\n",
    "print(\"Compressed size:\", len(compressed_data))\n",
    "\n",
    "print(data)\n",
    "print(compressed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building compressed train split\n",
      "Progress: 0.0%\n",
      "Progress: 10.0%\n",
      "Progress: 20.0%\n",
      "Progress: 30.0%\n",
      "Progress: 40.0%\n",
      "Progress: 50.0%\n",
      "Progress: 60.0%\n",
      "Progress: 70.0%\n",
      "Progress: 80.0%\n",
      "Progress: 90.0%\n",
      "Progress: 100.0%\n",
      "Stacking tensors and converting to numpy array\n"
     ]
    }
   ],
   "source": [
    "# Run train set back through model to get compressed embeddings train split\n",
    "\n",
    "compress_batch_size = 64\n",
    "D = train_input_array.shape[1]\n",
    "\n",
    "model = Network(64)\n",
    "\n",
    "checkpoint = torch.load(\"compressai_losses_final.pth\",map_location=\"cuda\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "print(\"Building compressed train split\")\n",
    "\n",
    "# for stacking tensors back into numpy array\n",
    "tensor_list = []\n",
    "\n",
    "compress_dataloader = DataLoader(train_input_array, batch_size=compress_batch_size, shuffle=False)\n",
    "for i_batch, batch in enumerate(compress_dataloader):\n",
    "        x = batch.to(\"cuda\")\n",
    "        x = x.to(torch.float)\n",
    "        x = x.reshape(compress_batch_size, 1, D)\n",
    "\n",
    "        y_hat, y_likelihoods = model.get_compressed_embeddings(x)\n",
    "\n",
    "        y_hat = y_hat.to(torch.int)\n",
    "\n",
    "        for i in range(y_hat.size(0)): \n",
    "                train_entry = y_hat[i, 0, :]  \n",
    "                tensor_list.append(train_entry)  \n",
    "\n",
    "        if i_batch % 1562 == 0:\n",
    "                print(\"Progress: \" + str((i_batch/1562)*10) + \"%\")\n",
    "\n",
    "print(\"Stacking tensors and converting to numpy array\")\n",
    "\n",
    "combined_tensor = torch.stack(tensor_list)\n",
    "compressed_train_embeddings = combined_tensor.detach().cpu().numpy()\n",
    "\n",
    "compressed_train_split_path = 'learned_compressed_train_split.npy'\n",
    "\n",
    "np.save(compressed_train_split_path, compressed_train_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building compressed test split\n",
      "Stacking tensors and converting to numpy array\n"
     ]
    }
   ],
   "source": [
    "# Run test set through model to get compressed embeddings test split\n",
    "\n",
    "compress_batch_size = 64\n",
    "D = test_input_array.shape[1]\n",
    "\n",
    "model = Network(64)\n",
    "\n",
    "checkpoint = torch.load(\"compressai_losses_final.pth\",map_location=\"cuda\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "print(\"Building compressed test split\")\n",
    "\n",
    "# for stacking tensors back into numpy array\n",
    "tensor_list = []\n",
    "\n",
    "compress_dataloader = DataLoader(test_input_array, batch_size=compress_batch_size, shuffle=False)\n",
    "for i_batch, batch in enumerate(compress_dataloader):\n",
    "        x = batch.to(\"cuda\")\n",
    "        x = x.to(torch.float)\n",
    "\n",
    "        if i_batch == 156:\n",
    "            x = x.reshape(16, 1, D)\n",
    "        else:\n",
    "            x = x.reshape(compress_batch_size, 1, D)\n",
    "                \n",
    "        y_hat, y_likelihoods = model.get_compressed_embeddings(x)\n",
    "\n",
    "        y_hat = y_hat.to(torch.int) # 16 bit int\n",
    "\n",
    "        for i in range(y_hat.size(0)): \n",
    "            test_entry = y_hat[i, 0, :]  \n",
    "            tensor_list.append(test_entry) \n",
    "\n",
    "        #if i_batch % 1562 == 0:\n",
    "            #print(\"Progress: \" + str((i_batch/1562)*10) + \"%\")\n",
    "\n",
    "print(\"Stacking tensors and converting to numpy array\")\n",
    "\n",
    "combined_tensor = torch.stack(tensor_list)\n",
    "compressed_test_embeddings = combined_tensor.detach().cpu().numpy()\n",
    "\n",
    "compressed_test_split_path = 'learned_compressed_test_split.npy'\n",
    "\n",
    "np.save(compressed_test_split_path, compressed_test_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load compressed embedding splits\n",
    "\n",
    "compressed_train_split_path = 'learned_compressed_train_split.npy'\n",
    "compressed_test_split_path = 'learned_compressed_test_split.npy'\n",
    "\n",
    "compressed_train_split_for_hnsw = np.load(compressed_train_split_path)\n",
    "\n",
    "#print(compressed_train_split_for_hnsw)\n",
    "\n",
    "#print(compressed_train_split_for_hnsw[0])\n",
    "\n",
    "#compressed_train_split_for_hnsw.shape[0]\n",
    "\n",
    "compressed_test_split_for_hnsw = np.load(compressed_test_split_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-181\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "print(min(compressed_test_split_for_hnsw.flatten()))\n",
    "print(max(compressed_test_split_for_hnsw.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import random, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = compressed_train_split_for_hnsw.shape[1]\n",
    "\n",
    "hnsw_indexer = faiss.index_factory(dim, \"HNSW\")\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnsw_indexer.train(compressed_train_split_for_hnsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnsw_indexer.add(compressed_train_split_for_hnsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[218., 219., 235., 252., 260., 270., 272., 272., 284., 288.],\n",
       "       [100., 116., 136., 144., 171., 179., 190., 206., 215., 216.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "distances, index = hnsw_indexer.search(compressed_test_split_for_hnsw[:2], k)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528129506"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size\n",
    "\n",
    "idx_file = open(\"./temp.index\", \"w\")\n",
    "idx_file.truncate(0)\n",
    "idx_file.close()\n",
    "faiss.write_index(hnsw_indexer, \"./temp.index\")\n",
    "file_size = os.path.getsize('./temp.index')\n",
    "file_size\n",
    "#528129506 528mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70636\n"
     ]
    }
   ],
   "source": [
    "# Relevancy - what percent of the K neighbor search results are in the top T correct closest neighbors\n",
    "\n",
    "k = 5 # number of returned neighbors for each embedding\n",
    "t = 25 # top X number of closest neighbors\n",
    "\n",
    "distances, index = hnsw_indexer.search(compressed_test_split_for_hnsw[:10000], k)\n",
    "\n",
    "relevantPercent = []\n",
    "\n",
    "i = 0\n",
    "for search_results in index:\n",
    "    closest_neighbors = neighbors[i]\n",
    "    \n",
    "    topIndexs = []\n",
    "    for x in range(t):\n",
    "        index_dict = closest_neighbors[x]\n",
    "        topIndexs.append(index_dict[\"index\"])\n",
    "\n",
    "    count = 0\n",
    "    for x in search_results:\n",
    "        if x in topIndexs:\n",
    "            count+=1\n",
    "\n",
    "    relevantPercent.append(count/k)\n",
    "    i=i+1\n",
    "    \n",
    "print(sum(relevantPercent) / len(relevantPercent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8198\n"
     ]
    }
   ],
   "source": [
    "# Recall@1\n",
    "\n",
    "k = 100 # number of returned neighbors for each embedding\n",
    "\n",
    "distances, index = hnsw_indexer.search(compressed_test_split_for_hnsw[:10000], k)\n",
    "\n",
    "count = 0\n",
    "\n",
    "i = 0\n",
    "for search_results in index:\n",
    "    closest_neighbors = neighbors[i]\n",
    "    \n",
    "    topIndexs = []\n",
    "    for x in range(1):\n",
    "        index_dict = closest_neighbors[x]\n",
    "        topIndexs.append(index_dict[\"index\"])\n",
    "\n",
    "    for x in search_results:\n",
    "        if x in topIndexs:\n",
    "            count+=1\n",
    "            break\n",
    "\n",
    "    i=i+1\n",
    "    \n",
    "print(count/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg search time:  0.0002955641746520996  seconds\n"
     ]
    }
   ],
   "source": [
    "# Search Speed\n",
    "\n",
    "total_time = 0\n",
    "iterations = 1000\n",
    "\n",
    "for x in range(iterations):\n",
    "\n",
    "    k = 25\n",
    "    index = random.randint(0, 9999)\n",
    "\n",
    "    input = np.empty((0,64))\n",
    "    input = np.vstack([input,compressed_test_split_for_hnsw[index]])\n",
    "\n",
    "    start_time = time.time()\n",
    "    distances, index = hnsw_indexer.search(input, k)\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += end_time - start_time\n",
    "\n",
    "\n",
    "print(\"avg search time: \", total_time/iterations, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Reconstruction Loss\n",
    "\n",
    "compress_batch_size = 64\n",
    "D = test_input_array.shape[1]\n",
    "\n",
    "model = Network(64)\n",
    "\n",
    "checkpoint = torch.load(\"compressai_losses_3.pth\",map_location=\"cuda\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "print(\"Test Reconstruction Loss:\")\n",
    "\n",
    "loss_arr = np.array([])\n",
    "mse_loss_arr = np.array([])\n",
    "\n",
    "lmbda = 1\n",
    "\n",
    "compress_dataloader = DataLoader(test_input_array, batch_size=compress_batch_size, shuffle=False)\n",
    "for i_batch, batch in enumerate(compress_dataloader):\n",
    "        x = batch.to(\"cuda\")\n",
    "        x = x.to(torch.float)\n",
    "\n",
    "        if i_batch == 156:\n",
    "            x = x.reshape(16, 1, D)\n",
    "        else:\n",
    "            x = x.reshape(compress_batch_size, 1, D)\n",
    "                \n",
    "        x_hat, y_likelihoods = model(x)\n",
    "\n",
    "        # bitrate of the quantized latent\n",
    "        N, _, L = x.size()\n",
    "        num_logits = N * L\n",
    "        bpp_loss = torch.log(y_likelihoods).sum() / (-math.log(2) * num_logits)\n",
    "\n",
    "        # mean square error\n",
    "        mse_loss = F.mse_loss(x, x_hat)\n",
    "\n",
    "        # final loss term\n",
    "        loss = mse_loss + lmbda * bpp_loss\n",
    "\n",
    "        loss_arr = np.append(loss_arr,loss.detach().cpu().numpy())\n",
    "        mse_loss_arr = np.append(mse_loss_arr,mse_loss.detach().cpu().numpy())\n",
    "\n",
    "print(np.average(loss_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode and Encode speed\n",
    "\n",
    "compress_batch_size = 64\n",
    "D = test_input_array.shape[1]\n",
    "\n",
    "model = Network(64)\n",
    "\n",
    "checkpoint = torch.load(\"compressai_losses_3.pth\",map_location=\"cuda\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "print(\"Encode and Decode Time:\")\n",
    "\n",
    "total_encode_time_array = np.array([])\n",
    "total_decode_time_array = np.array([])\n",
    "total_encode_time = 0\n",
    "total_decode_time = 0\n",
    "\n",
    "compress_dataloader = DataLoader(test_input_array, batch_size=compress_batch_size, shuffle=False)\n",
    "for i_batch, batch in enumerate(compress_dataloader):\n",
    "        x = batch.to(\"cuda\")\n",
    "        x = x.to(torch.float)\n",
    "\n",
    "        if i_batch == 156:\n",
    "            x = x.reshape(16, 1, D)\n",
    "        else:\n",
    "            x = x.reshape(compress_batch_size, 1, D)\n",
    "\n",
    "        start_time = time.time()\n",
    "        y_hat, y_likelihoods = model.get_compressed_embeddings(x)\n",
    "        end_time = time.time()\n",
    "        total_encode_time += end_time - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        x_hat = model.decode_compressed_embeddings(y_hat)\n",
    "        end_time = time.time()\n",
    "        total_decode_time += end_time - start_time\n",
    "\n",
    "        total_encode_time_array = np.append(total_encode_time_array,total_encode_time)\n",
    "        total_decode_time_array = np.append(total_decode_time_array,total_decode_time)\n",
    "\n",
    "print(\"Avg encode time: \" + str(np.average(total_encode_time_array)))\n",
    "print(\"Avg decode time: \" + str(np.average(total_decode_time_array)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
